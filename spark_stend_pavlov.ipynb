{
  "metadata": {
    "name": "pavlov",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\nfrom pyspark.sql import SparkSession\n\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import IntegerType, FloatType, DateType\n\nspark \u003d SparkSession.builder.master(\"local[*]\").appName(\u0027Led_Zeppelin\u0027).getOrCreate()"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\ndata \u003d spark.read.csv(\"hdfs://vm-dlake2-m-1.test.local/user/yakupov/data/recommendations.csv\", sep\u003d\u0027,\u0027, header\u003dTrue)\n\nfor col_name in data.columns:\n    if col_name in (\u0027is_recommended\u0027, ):\n        continue\n    data \u003d data.withColumn(col_name, F.col(col_name).cast(\"int\"))\n\ndata.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\ngames \u003d spark.read.csv(\"hdfs://vm-dlake2-m-1.test.local/user/pavlov/data/games.csv\", sep\u003d\u0027,\u0027, header\u003dTrue)\ngames \u003d games.withColumn(\u0027app_id\u0027, F.col(\u0027app_id\u0027).cast(\"int\"))\n\ngames.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n\nmetadata \u003d spark.read.json(\"hdfs://vm-dlake2-m-1.test.local/user/pavlov/data/games_metadata.json\")\n\nmetadata.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# games \u003d games.withColumn(\u0027app_id\u0027, F.col(\u0027app_id\u0027).cast(\"int\"))\n\n# for col_name in data.columns:\n#     if col_name in (\u0027is_recommended\u0027, ):\n#         continue\n#     data \u003d data.withColumn(col_name, F.col(col_name).cast(\"int\"))\n\ndata.select([\u0027helpful\u0027, \u0027funny\u0027, \u0027hours\u0027]).describe().show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# отфильтруем значения, которые больше 0.5% квантиля\nquantiles \u003d data.approxQuantile([\u0027helpful\u0027, \u0027funny\u0027, \u0027hours\u0027], [0.995], 0.05)\n\nfor idx, col_name in enumerate([\u0027helpful\u0027, \u0027funny\u0027, \u0027hours\u0027]):\n    print(f\u0027{col_name} --\u003e {quantiles[idx]}\u0027)\n    data \u003d data.filter(F.col(col_name) \u003c quantiles[idx][0])\n\ndata.select([\u0027helpful\u0027, \u0027funny\u0027, \u0027hours\u0027]).describe().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\ndf_grp \u003d data.groupBy(\u0027app_id\u0027, \u0027is_recommended\u0027).agg(\n    F.mean(\u0027hours\u0027).alias(\u0027hours_mean\u0027),\n    F.expr(\u0027percentile_approx(hours, 0.5)\u0027).alias(\u0027hours_median\u0027),\n    F.countDistinct(\u0027user_id\u0027).alias(\u0027users\u0027)\n)\n\ndf_grp \u003d df_grp.fillna(0)\n\ndata.groupBy(\u0027is_recommended\u0027).agg(\n    F.expr(\u0027percentile_approx(hours, 0.5)\u0027).alias(\u0027median_hours\u0027),\n    F.mean(\u0027hours\u0027).alias(\u0027mean_hours\u0027),\n    F.max(\u0027hours\u0027).alias(\u0027max_hours\u0027)\n).show()"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\ndf_grp.approxQuantile(\u0027users\u0027, [0.25], 0.05)"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# Посмотрим на самые популярные жанры игр (отфильтруем игры, у которых игроков менее квартили)\ndf \u003d df_grp.filter(F.col(\u0027users\u0027) \u003e 5)\n# df \u003d df.join(metadata.select(\u0027app_id\u0027, \u0027tags\u0027), on\u003d\u0027app_id\u0027)\n# df \u003d df.join(games.select(\u0027app_id\u0027, \u0027title\u0027), on\u003d\u0027app_id\u0027)\n\n# df.select([\u0027hours_mean\u0027, \u0027hours_median\u0027, \u0027users\u0027]).describe().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# TOP-10 игр, в которых играло больше всего пользователей\n# df.orderBy(F.col(\u0027users\u0027).desc()).show(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# TOP-10 игр, в которых играло больше всего пользователей\ntop \u003d df.sort(F.desc(\"users\")).limit(10)\ntop.show(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\ntop_games \u003d [row.app_id for row in top.select(\u0027app_id\u0027).collect()]\napp_games \u003d games.filter(F.col(\"app_id\").isin(top_games)).select(\u0027app_id\u0027, \u0027title\u0027)\napp_games.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\ntop_apps \u003d top.join(app_games, on\u003d\u0027app_id\u0027)\ntitle_users \u003d [row.title for row in top_apps.select(\u0027title\u0027).collect()]\ntop_apps.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n\n# TOP-10 игр, за которыми было затрачено больше всего времени в среднем\ntop \u003d df.sort(F.desc(\"hours_mean\")).limit(10)\ntop.show(10)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\ntop_games \u003d [row.app_id for row in top.select(\u0027app_id\u0027).collect()]\napp_games \u003d games.filter(F.col(\"app_id\").isin(top_games)).select(\u0027app_id\u0027, \u0027title\u0027)\napp_games.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\ntop_apps \u003d top.join(app_games, on\u003d\u0027app_id\u0027)\ntitle_hours \u003d [row.title for row in top_apps.select(\u0027title\u0027).collect()]\ntop_apps.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n# Только одна игра, которая входит в TOP-10 по количеству играющих и затраченных часов\nset(title_users) \u0026 set(title_hours)"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n"
    }
  ]
}